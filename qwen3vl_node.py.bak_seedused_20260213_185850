"""
Qwen3-VL Uncensored - ComfyUI Node
===================================
Der eigentliche ComfyUI Custom Node

Autor: Martin + Claude Coach
Datum: 2026-02-13
"""

import torch
import numpy as np
from PIL import Image
import tempfile
from pathlib import Path

PRESET_PROMPTS = [
    "ðŸ–¼ï¸ Tags",
    "ðŸ–¼ï¸ Simple Description",
    "ðŸ–¼ï¸ Detailed Description",
    "ðŸ–¼ï¸ Ultra Detailed Description",
    "ðŸŽ¬ Cinematic Description",
    "ðŸ–¼ï¸ Detailed Analysis",
    "ðŸ“¹ Video Summary",
    "ðŸ“– Short Story",
    "ðŸª„ Prompt Refine & Expand",
]


from .llama_wrapper import LlamaWrapper


class Qwen3VLPromptGenerator:
    """
    ComfyUI Node: Qwen3-VL Prompt Generator (Uncensored)
    
    Modes:
    - enhance:    Text â†’ Enhanced Text
    - describe:   Image â†’ Prompt
    - multimodal: Text + Image â†’ Enhanced Prompt
    """
    
    def __init__(self):
        self.llama = None  # Lazy init (erst bei erster Nutzung)
    
    @classmethod
    def INPUT_TYPES(cls):
        """
        Definiert die Input-Ports des Nodes
        
        ComfyUI zeigt diese in der UI an
        """
        return {
            "required": {
                "mode": (["enhance", "describe", "multimodal"], {
                    "default": "enhance"
                }),
            "preset_prompt": (PRESET_PROMPTS, {"default": "ðŸ–¼ï¸ Detailed Analysis"}),
            },
            "optional": {
                "text": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "Enter text prompt to enhance..."
                }),
                "image": ("IMAGE",),  # ComfyUI Bild-Tensor
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05
                }),
                "max_tokens": ("INT", {
                    "default": 400,
                    "min": 50,
                    "max": 1000,
                    "step": 50
                }),
            "use_preset_tokens": ("BOOLEAN", {"default": True}),
            "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            "control_after_generate": (["fixed", "increment", "decrement", "randomize"], {"default": "randomize"}),
            "keep_model_loaded": ("BOOLEAN", {"default": False}),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("generated_prompt",)
    FUNCTION = "generate_prompt"
    CATEGORY = "prompt/qwen3vl"
    
    def generate_prompt(self, 
        mode: str,
        text: str = "",
        image = None,
        temperature: float = 0.7,
        max_tokens: int = 400, preset_prompt="ðŸ–¼ï¸ Detailed Analysis", use_preset_tokens=True, seed=0, control_after_generate="randomize", keep_model_loaded=False):
        # --- preset safety locals (required because ComfyUI passes kwargs) ---
        preset_prompt=locals().get('preset_prompt', 'ðŸ–¼ï¸ Detailed Analysis') if 'preset_prompt' in locals() else "ðŸ–¼ï¸ Detailed Analysis"
        use_preset_tokens=bool(locals().get('use_preset_tokens', True)) if 'use_preset_tokens' in locals() else True
        """
        Haupt-Funktion des Nodes
        
        Args:
            mode: "enhance" / "describe" / "multimodal"
            text: Optional text prompt
            image: Optional ComfyUI image tensor
            temperature: KreativitÃ¤t
            max_tokens: Max Antwort-LÃ¤nge
            
        Returns:
            Tuple mit (generated_prompt_string,)
        """
        
        # Lazy init des LlamaWrapper
        if self.llama is None:
            try:
                self.llama = LlamaWrapper()
                print("[Qwen3-VL] âœ… LlamaWrapper initialisiert")
            except Exception as e:
                error_msg = f"âŒ ERROR: LlamaWrapper init failed:\n{str(e)}"
                print(f"[Qwen3-VL] {error_msg}")
                return (error_msg,)
        
        # Update config mit User-Parametern
        from . import config
        config.TEMPERATURE = temperature
        config.MAX_TOKENS = max_tokens
        
        # Mode-Routing
        try:
            if mode == "enhance":
                result = self._mode_enhance(text)
            elif mode == "describe":
                result = self._mode_describe(image)
            elif mode == "multimodal":
                result = self._mode_multimodal(text, image)
            else:
                result = f"âŒ ERROR: Unknown mode '{mode}'"
            
            print(f"[Qwen3-VL] Generated prompt ({len(result)} chars)")
            return (result, next_seed)
        except Exception as e:
            error_msg = f"âŒ ERROR in {mode} mode:\n{str(e)}"
            print(f"[Qwen3-VL] {error_msg}")
            return (error_msg,)
    
    def _mode_enhance(self, text: str) -> str:
        """Mode: enhance - Text â†’ Enhanced Text"""
        if not text or not text.strip():
            return "âŒ ERROR: Text input required for 'enhance' mode!"
        
        print(f"[Qwen3-VL] Enhancing text: '{text[:50]}...'")
        return self.llama.enhance_prompt(text, preset_prompt=locals().get('preset_prompt', 'ðŸ–¼ï¸ Detailed Analysis'), use_preset_tokens=bool(locals().get('use_preset_tokens', True)), seed=seed_used)
    
    def _mode_describe(self, image) -> str:
        """Mode: describe - Image â†’ Prompt"""
        if image is None:
            return "âŒ ERROR: Image input required for 'describe' mode!"
        
        # Konvertiere ComfyUI Tensor â†’ PIL Image â†’ temporÃ¤re Datei
        image_path = self._tensor_to_tempfile(image)
        
        print(f"[Qwen3-VL] Describing image: {image_path}")
        result = self.llama.describe_image(image_path, preset_prompt=locals().get('preset_prompt', 'ðŸ–¼ï¸ Detailed Analysis'), use_preset_tokens=bool(locals().get('use_preset_tokens', True)), seed=seed_used)
        
        # Cleanup
        image_path.unlink()
        
        return (result, next_seed)
    def _mode_multimodal(self, text: str, image) -> str:
        """Mode: multimodal - Text + Image â†’ Enhanced Prompt"""
        if not text or not text.strip():
            return "âŒ ERROR: Text input required for 'multimodal' mode!"
        if image is None:
            return "âŒ ERROR: Image input required for 'multimodal' mode!"
        
        # Konvertiere ComfyUI Tensor â†’ PIL Image â†’ temporÃ¤re Datei
        image_path = self._tensor_to_tempfile(image)
        
        print(f"[Qwen3-VL] Multimodal: text='{text[:50]}...' + image")
        result = self.llama.multimodal_enhance(text, image_path, preset_prompt=locals().get('preset_prompt', 'ðŸ–¼ï¸ Detailed Analysis'), use_preset_tokens=bool(locals().get('use_preset_tokens', True)), seed=seed_used)
        
        # Cleanup
        image_path.unlink()
        
        return (result, next_seed)
    def _tensor_to_tempfile(self, image_tensor) -> Path:
        """
        Konvertiert ComfyUI Image-Tensor zu temporÃ¤rer Bild-Datei
        
        ComfyUI Tensors sind: [batch, height, width, channels]
        Wir nehmen nur das erste Bild im Batch
        """
        
        # Nimm erstes Bild im Batch
        if len(image_tensor.shape) == 4:
            img = image_tensor[0]
        else:
            img = image_tensor
        
        # Konvertiere zu numpy array
        img_np = (img.cpu().numpy() * 255).astype(np.uint8)
        
        # Erstelle PIL Image
        pil_img = Image.fromarray(img_np)
        
        # Speichere in temporÃ¤re Datei
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        temp_path = Path(temp_file.name)
        pil_img.save(temp_path)
        temp_file.close()
        
        return temp_path


# Node-Mapping fÃ¼r ComfyUI
NODE_CLASS_MAPPINGS = {
    "Qwen3VLPromptGenerator": Qwen3VLPromptGenerator
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Qwen3VLPromptGenerator": "Qwen3-VL Prompt Generator (Uncensored) ðŸ”“"
}
