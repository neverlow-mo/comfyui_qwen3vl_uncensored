# Qwen3-VL Prompt Generator (Uncensored) ğŸ”“

**ComfyUI Custom Node** fÃ¼r zensurfreie Prompt-Generierung mit Qwen3-VL-30B

---

## ğŸ¯ Features

- âœ… **Text Enhancement**: Verbessert einfache Prompts â†’ detaillierte SD-Prompts
- âœ… **Image Description**: Analysiert Bilder â†’ generiert Prompts
- âœ… **Multimodal**: Kombiniert Text + Bild â†’ optimierte Prompts
- âœ… **Zensurfrei**: Ablitiertes Modell (keine Content-Filter!)
- âœ… **RTX 5090 optimiert**: ~225 t/s Generation-Speed
- âœ… **30B Parameter**: Sehr intelligente Prompt-Generierung

---

## ğŸ“¦ Installation

### 1. Voraussetzungen

- âœ… llama.cpp kompiliert (mit CUDA)
- âœ… Qwen3-VL-30B-abliterated-Q4_K_M GGUF-Modell
- âœ… MMProj-File (fÃ¼r Vision)

### 2. Installation

```bash
cd ~/ai/comfy-cu130/custom_nodes/
git clone <dein-repo> comfyui-qwen3vl-uncensored
# ODER kopiere den Ordner manuell
```

### 3. Konfiguration

Passe `config.py` an:

```python
LLAMA_CLI = Path.home() / "ai" / "llama-cpp-core" / "build" / "bin" / "llama-cli"
MODEL_PATH = Path("/pfad/zu/deinem/modell.gguf")
MMPROJ_PATH = Path("/pfad/zu/deinem/mmproj.gguf")
```

### 4. ComfyUI neu starten

Der Node erscheint unter: **Add Node â†’ prompt â†’ qwen3vl**

---

## ğŸ¬ Nutzung

### Mode 1: **enhance** (Text â†’ Enhanced Text)

```
Input:  "a cat"
Output: "a majestic fluffy cat, sitting on windowsill, golden hour lighting, 
         photorealistic, highly detailed fur texture, bokeh background, 
         professional photography, 8k uhd, masterpiece, best quality"
```

**Use Case**: Verbessere kurze/einfache Prompts

---

### Mode 2: **describe** (Image â†’ Prompt)

```
Input:  [Bild einer Landschaft]
Output: "breathtaking mountain landscape, snow-capped peaks, crystal clear lake 
         in foreground, dramatic clouds, sunset lighting, wide angle shot, 
         vibrant colors, highly detailed, masterpiece, 8k"
```

**Use Case**: Erstelle Prompts aus Referenzbildern

---

### Mode 3: **multimodal** (Text + Image â†’ Enhanced Prompt)

```
Input Text:  "make it cyberpunk"
Input Image: [Stadtbild]
Output:      "futuristic cyberpunk cityscape, neon lights, holographic billboards, 
              rain-soaked streets, night scene, dark atmosphere, blade runner style, 
              highly detailed, cinematic lighting, 8k uhd, masterpiece"
```

**Use Case**: Kombiniere deine Idee mit einem Referenzbild

---

## âš™ï¸ Parameter

| Parameter | Beschreibung | Default |
|-----------|--------------|---------|
| `mode` | enhance / describe / multimodal | enhance |
| `text` | Text-Prompt (optional je nach Mode) | - |
| `image` | Bild (optional je nach Mode) | - |
| `temperature` | KreativitÃ¤t (0.0 = deterministisch, 1.0 = kreativ) | 0.7 |
| `max_tokens` | Maximale Antwort-LÃ¤nge | 400 |

---

## ğŸ”’ Zensurfreiheit

Dieses Node nutzt ein **ablitiertes** (uncensored) Modell.

**Was das bedeutet:**
- âœ… Keine Content-Filter
- âœ… Beschreibt objektiv, was du anforderst
- âœ… Kein "I cannot help with that"
- âœ… FÃ¼r professionelle/kÃ¼nstlerische Nutzung

**Verantwortung**: Du bist fÃ¼r die Nutzung verantwortlich!

---

## ğŸš€ Performance

**Hardware**: RTX 5090 (32GB VRAM)  
**Modell**: Qwen3-VL-30B Q4_K_M  
**Speed**: ~225 t/s Generation  
**VRAM**: ~19GB (bleibt 13GB frei)

**Schneller als die meisten Online-APIs!** âš¡

---

## ğŸ› Troubleshooting

### "llama-cli nicht gefunden"
â†’ Passe `LLAMA_CLI` Pfad in `config.py` an

### "Modell nicht gefunden"
â†’ Passe `MODEL_PATH` in `config.py` an

### "Vision funktioniert nicht"
â†’ PrÃ¼fe ob `MMPROJ_PATH` existiert

### Node erscheint nicht in ComfyUI
â†’ ComfyUI Console checken (Fehlerme


ldungen)
â†’ `python config.py` ausfÃ¼hren (zeigt Pfad-Fehler)

---

## ğŸ“ Credits

- **Modell**: Qwen3-VL-30B von Alibaba (abliterated by tvall43)
- **Engine**: llama.cpp by ggerganov
- **Node**: Martin + Claude Coach (2026-02-13)

---

## ğŸ“œ Lizenz

MIT License - Nutze es wie du willst!

**Hinweis**: Das Modell selbst hat eigene Lizenzen (check HuggingFace)

---

## ğŸ”— Links

- [Qwen3-VL Modell](https://huggingface.co/tvall43/Huihui-Qwen3-VL-30B-A3B-Instruct-abliterated-Q4_K_M-GGUF)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [ComfyUI](https://github.com/comfyanonymous/ComfyUI)

---

**Viel SpaÃŸ mit zensurfreier Prompt-Generierung! ğŸ”“ğŸš€**
